{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backers_count', 'final_status'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns.tolist()) - set(test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73568\n",
       "1    34561\n",
       "Name: final_status, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking imbalance\n",
    "train['final_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre Proessing\n",
    "train_id, test_id = train['project_id'], test['project_id']\n",
    "target = train['final_status']\n",
    "train = train.drop(['final_status', 'backers_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imbalance ratio\n",
    "weight = float(np.sum(target == 0)) / float(np.sum(target == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concating train and test into one\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# Text columns\n",
    "text= data[['project_id','name', 'desc', 'keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols=['project_id', 'name', 'desc', 'keywords', 'goal', 'disable_communication', 'country', 'currency', 'deadline', 'state_changed_at', 'created_at', 'launched_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 171594 entries, 0 to 171593\n",
      "Data columns (total 12 columns):\n",
      "project_id               171594 non-null object\n",
      "name                     171593 non-null object\n",
      "desc                     171582 non-null object\n",
      "keywords                 171594 non-null object\n",
      "goal                     171594 non-null float64\n",
      "disable_communication    171594 non-null bool\n",
      "country                  171594 non-null object\n",
      "currency                 171594 non-null object\n",
      "deadline                 171594 non-null int64\n",
      "state_changed_at         171594 non-null int64\n",
      "created_at               171594 non-null int64\n",
      "launched_at              171594 non-null int64\n",
      "dtypes: bool(1), float64(1), int64(4), object(6)\n",
      "memory usage: 14.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import readability\n",
    "\n",
    "def computeRead(text):\n",
    "    rd = readability.Readability(text)\n",
    "    score = rd.FleschKincaidGradeLevel()\n",
    "    return int(score)\n",
    "def ARIscore(text):\n",
    "    rd = readability.Readability(text)\n",
    "    score = rd.ARI()\n",
    "    return float(score)\n",
    "def LIXscore(text):\n",
    "    rd = readability.Readability(text)\n",
    "    score = rd.LIX()\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['readscore'] = data['desc'].apply(lambda d: computeRead(str(d)))\n",
    "data['ariscore'] = data['desc'].apply(lambda d: ARIscore(str(d)))\n",
    "data['lixscore'] = data['desc'].apply(lambda d: LIXscore(str(d)))\n",
    "\n",
    "data['readscoreX'] = data['name'].apply(lambda d: computeRead(str(d)))\n",
    "data['ariscoreX'] = data['name'].apply(lambda d: ARIscore(str(d)))\n",
    "data['lixscoreX'] = data['name'].apply(lambda d: LIXscore(str(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def compoundScore(text):\n",
    "    res = analyzer.polarity_scores(text)\n",
    "    return float(res['compound'])\n",
    "def negSent(text):\n",
    "    res = analyzer.polarity_scores(text)\n",
    "    return float(res['neg'])\n",
    "def posSent(text):\n",
    "    res = analyzer.polarity_scores(text)\n",
    "    return float(res['pos'])\n",
    "def neuSent(text):\n",
    "    res = analyzer.polarity_scores(text)\n",
    "    return float(res['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['compoundScore'] = data['desc'].apply(lambda d: compoundScore(str(d)))\n",
    "data['negSent'] = data['desc'].apply(lambda d: negSent(str(d)))\n",
    "data['posSent'] = data['desc'].apply(lambda d: posSent(str(d)))\n",
    "data['neuSent'] = data['desc'].apply(lambda d: neuSent(str(d)))\n",
    "\n",
    "data['compoundScoreX'] = data['name'].apply(lambda d: compoundScore(str(d)))\n",
    "data['negSentX'] = data['name'].apply(lambda d: negSent(str(d)))\n",
    "data['posSentX'] = data['name'].apply(lambda d: posSent(str(d)))\n",
    "data['neuSentX'] = data['name'].apply(lambda d: neuSent(str(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['project_id', 'name', 'desc', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting attributes from dates\n",
    "import datetime\n",
    "data['deadline'] =  pd.to_datetime(data['deadline'], unit='s')\n",
    "data['state_changed_at'] =  pd.to_datetime(data['state_changed_at'], unit='s')\n",
    "data['created_at'] =  pd.to_datetime(data['created_at'], unit='s')\n",
    "data['launched_at'] =  pd.to_datetime(data['launched_at'], unit='s')\n",
    "\n",
    "# deadline\n",
    "data['deadline_month'] = data['deadline'].dt.month\n",
    "data['deadline_day'] = data['deadline'].dt.day\n",
    "data['deadline_year'] = data['deadline'].dt.year\n",
    "\n",
    "# state_changed_at\n",
    "data['state_changed_at_month'] = data['state_changed_at'].dt.month\n",
    "data['state_changed_at_day'] = data['state_changed_at'].dt.day\n",
    "data['state_changed_at_year'] = data['state_changed_at'].dt.year\n",
    "\n",
    "# created_at\n",
    "data['created_at_month'] = data['created_at'].dt.month\n",
    "data['created_at_day'] = data['created_at'].dt.day\n",
    "data['created_at_year'] = data['created_at'].dt.year\n",
    "\n",
    "# launched_at\n",
    "data['launched_at_month'] = data['launched_at'].dt.month\n",
    "data['launched_at_day'] = data['launched_at'].dt.day\n",
    "data['launched_at_year'] = data['launched_at'].dt.year\n",
    "\n",
    "\n",
    "# deadline- state_changed_at\n",
    "data['deadline_margin']= data['deadline'].dt.date- data['state_changed_at'].dt.date\n",
    "data['deadline_margin'] = data['deadline_margin'].astype('str')\n",
    "data['deadline_margin']= data['deadline_margin'].apply(lambda x: x.split(' ', 1)[0])\n",
    "data['deadline_margin'] = data['deadline_margin'].astype('int64')\n",
    "\n",
    "#launched_at- created_at\n",
    "data['launch_margin']= data['launched_at'].dt.date- data['created_at'].dt.date\n",
    "data['launch_margin'] = data['launch_margin'].astype('str')\n",
    "data['launch_margin']= data['launch_margin'].apply(lambda x: x.split(' ', 1)[0])\n",
    "data['launch_margin'] = data['launch_margin'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    print(str(col)+':')\n",
    "    print('____________________________________')\n",
    "    print(data[col].value_counts())\n",
    "    print('____________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def currency_conversion_ratio(x):\n",
    "    if x=='USD':\n",
    "        return 1.000       #Setting USD as unit\n",
    "    if x=='GBP':\n",
    "        return 1.390\n",
    "    if x=='EUR':\n",
    "        return 1.220\n",
    "    if x=='CAD':\n",
    "        return 0.800\n",
    "    if x=='AUD':\n",
    "        return 0.800\n",
    "    if x=='SEK':\n",
    "        return 0.120\n",
    "    if x=='NZD':\n",
    "        return 0.730\n",
    "    if x=='DKK':\n",
    "        return 0.160\n",
    "    if x=='NOK':\n",
    "        return 0.130\n",
    "    if x=='CHF':\n",
    "        return 1.040\n",
    "    if x=='MXN':\n",
    "        return 0.054\n",
    "    if x=='SGD':\n",
    "        return 0.760\n",
    "    if x=='HKD':\n",
    "        return 0.130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['conversion_ratio']=data['currency'].apply(lambda x: currency_conversion_ratio(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['goal']=data['goal']*data['conversion_ratio']\n",
    "data = data.drop(['conversion_ratio', 'deadline', 'state_changed_at', 'created_at', 'launched_at'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "from sklearn import preprocessing \n",
    "for i in data.columns: \n",
    "    if data[i].dtype=='object': \n",
    "        encoder = preprocessing.LabelEncoder() \n",
    "        encoder.fit(list(data[i].values)) \n",
    "        data[i] = encoder.transform(list(data[i].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting back into train and test\n",
    "train = data[:len(train)]\n",
    "test  = data[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 4: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "gbm = lgb.LGBMClassifier(n_estimators=2900, max_depth=3, subsample=0.7, colsample_bytree= 0.7, scale_pos_weight=weight)\n",
    "gbm = gbm.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = gbm.predict_proba(test)\n",
    "prediction = prediction[:,1]\n",
    "prediction[prediction>=0.5]=1\n",
    "prediction[prediction<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'project_id': test_id, 'final_status': prediction})\n",
    "sub = sub[['project_id', 'final_status']]\n",
    "filename = 'prediction.csv'\n",
    "sub.to_csv(filename, index=False)\n",
    "FileLink(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
